{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "  root=\"data\",\n",
    "  train =True,\n",
    "  download = True,\n",
    "  transform=ToTensor(),\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "for X, y in test_dataloader :\n",
    "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Initializing a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From another tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.5660, 0.6474],\n",
      "        [0.5716, 0.4188]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With random or constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.9239, 0.1170, 0.5714],\n",
      "        [0.2597, 0.9425, 0.0952]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Attributes(속성) of a Tensor\n",
    "\n",
    "텐서의 속성은  \n",
    "    \n",
    "        shape(모양)\n",
    "        dtype(datatype, 자료형)\n",
    "        device(저장되는 장치)\n",
    "\n",
    "  이 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Operations on Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **텐서의 이동**\n",
    "  \n",
    "  텐서는 `to` 메서드를 이용해 CPU에서 GPU로 이동이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#   tensor = tensor.to(\"cuda\")\n",
    "\n",
    "# 맥북이라면\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  tensor = tensor.to(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **NumPy식 표준 인덱싱과 슬라이싱**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First Column: tensor([1., 1., 1., 1.])\n",
      "Last Column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First Column: {tensor[:,0]}\")\n",
    "print(f\"Last Column: {tensor[...,-1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **텐서 합치기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4])\n",
      "torch.Size([4, 12])\n",
      "torch.Size([3, 4, 4])\n",
      "torch.Size([4, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim = 0) # dim = 0 means concatenate tensor along column dim\n",
    "print(t1.shape)\n",
    "\n",
    "t2 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
    "print(t2.shape)\n",
    "\n",
    "t3 = torch.stack([tensor, tensor, tensor], dim = 0) # torch.stack: concatenate with new dim\n",
    "print(t3.shape)\n",
    "\n",
    "t4 = torch.stack([tensor, tensor, tensor], dim=1)\n",
    "print(t4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **산술 연산**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "# y1, y2, y3 will have the same value\n",
    "y1 = tensor @ tensor.T \n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# element-wise product\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **단일-요소(single-element) 텐서**  \n",
    "\n",
    "  텐서의 모든 값을 집계(aggregate)하여 요소가 하나인 텐서는 `item()` 메서드를 사용해 Python 숫자 값으로 변환 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. Bridge with NumPy\n",
    "\n",
    "CPU상의 텐서와 NumPy배열은 **메모리 공간을 공유**하기 떄문에, 하나를 변경하면 다른 하나도 변경된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Tensor to NumPy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n",
      "t: tensor([3., 3., 3., 3., 3.])\n",
      "n: [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "np.add(n,1,out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **NumPy array to Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [2. 2. 2. 2. 2.]\n",
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "np.add(n,1,out=n)\n",
    "print(f\"n: {n}\")\n",
    "print(f\"t: {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datasets & DataLoaders\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 나은 가독성(Readability)와 모듈성(modularity)을 위해, 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적이다.  \n",
    "이를 위해 pytorch에서는 2가지 데이터 기본 요소를 제공한다. \n",
    "\n",
    "\n",
    "`torch.utils.data.Dataset` : 샘플과 정답(label)을 저장  \n",
    "\n",
    "`torch.utils.data.DataLoader` : `dataset`을 `iterable`(순회 가능한 객체)로 감싸는 역할  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Loading a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Fashion-MNIST` 데이터셋을 불러온다. 각 예제는 28x28 Grayscale Image와 10 Class중 하나인 Label로 구성된다.  \n",
    "\n",
    "다음 매개변수들을 사용하여 `FashionMNIST` 데이터셋을 불러온다.  \n",
    "\n",
    "* `root`: 학습/테스트 데이터가 저장되는 경로\n",
    "* `train`: 학습용/테스트용 데이터셋 여부 지정\n",
    "* `download=True`: `root`에 데이터가 없는 경우 다운로드\n",
    "* `transform` `target_transform`: 특징(feature)과 정답(label) 변형(transform)을 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "  root=\"data\",\n",
    "  train=True,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Iterating and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols*rows+1):\n",
    "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "  img, label = training_data[sample_idx]\n",
    "  figure.add_subplot(rows, cols, i)\n",
    "  plt.title(labels_map[label])\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Creating a Custom Dataset for your files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 정의 Dataset 클래스는 반드시 3개의 함수를 구현해야 한다.  \n",
    "\n",
    "* `__init__`\n",
    "* `__len__`\n",
    "* `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "    self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
    "    self.img_dir = img_dir\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.img_labels)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "    image = read_image(img_path)\n",
    "    label = self.img_labels.iloc[idx,1]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    if self.target_transform:\n",
    "      label = self.target_transform(label)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **\\_\\_init\\_\\_**\n",
    "\n",
    "**\\_\\_init\\_\\_** 함수는 Dataset 객체가 생성(instantiate)될 때 한 번만 실행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **\\_\\_len\\_\\_**  \n",
    "\n",
    "`__len__` 함수는 데이터셋의 샘플 개수를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **\\_\\_getitem\\_\\_**  \n",
    "\n",
    "`__getitem__` 함수는 주어진 인덱스에 해당하는 샘플을 데이터셋에서 불러오고, 반환한다.  \n",
    "인덱스를 기반 디스크에서 이미지의 위치를 식별,   \n",
    "`read_image`를 사용하여 이미지를 텐서로 변환,  \n",
    "`self.img_labels`의 csv데이터로부터 label을 가져오고,  \n",
    "(해당하는 경우) transform 함수를 호출한 뒤,  \n",
    "텐서 이미지와 라벨을 Python Dict형으로 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습할 때, 샘플들을 minibatch로 전달하고, 매 epoch마다 데이터를 섞어서 overfit을 막고, Python의 Multiprocessing을 사용해 데이터 검색 속도를 높이려 한다.  \n",
    "\n",
    "`DataLoader`는 간단한 API로 이 과정을 추상화한 순회 가능한 객체(iterable)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = 64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader`에 데이터셋을 불러온 뒤, 필요에 따라 데이터셋을 순회(iterate)할 수 있다.  \n",
    "\n",
    "아래의 각 순회(iteration)은 `train_features`(각각 `batch_size=64`의 feature과 label을 포함)와 `train_labels`의 batch를 반환한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw Data가 항상 ML Algorithm 학습에 필요한 최종 처리가 된 형태로 제공되지는 않는다. 이에 **Transform**을 해서 데이터를 조작, 학습에 적합하게 만든다.  \n",
    "\n",
    "모든 TorchVision 데이터셋은 Transformation Logic을 갖는 callable(호출 가능한 객체)를 받는 매개변수 2개를 갖는다.\n",
    "* `transform`: feature를 변형\n",
    "* `target_transform`: label을 변형\n",
    "\n",
    "FashionMNIST의 feature은 PIL Image 형식이고, label은 integer이다. 학습을 위해서는 normalized tensor 형태의 feature와 one-hot encoded tensor 형태의 label이 필요하다. 이를 위해 `ToTensor`와 `Lambda`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "  root = \"data\",\n",
    "  train=True,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    "  target_transform = Lambda(lambda y : torch.zeros(10, dtype=torch.float).scatter_(0,torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ToTensor()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ToTensor()`은 PIL Image나 NumPy `ndarray`를 `FloatTensor`로 변환하고, 이미지 픽셀의 크기(intensity) 값을 [0.,1.] 범위로 비례하여 조정한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 정의 lambda함수를 적용한다.  \n",
    "\n",
    "먼저 크기 10짜리 zero tensor를 만들고, `scatter_`를 호출하여 주어진 정답 y에 해당하는 인덱스에 `value=1`을 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망은 layer(계층), module(모듈)로 구성되어 있다. PyTorch의 모든 모듈은 `nn.Module`의 하위 클래스이다. 신경망은 다른 모듈(layers)들을 포함하고 있는 모듈 그 자체이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Get Device for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using \"mps\" device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "  \"cuda\" \n",
    "  if torch.cuda.is_available()\n",
    "  else \"mps\"\n",
    "  if torch.backends.mps.is_available()\n",
    "  else \"cpu\"\n",
    ")\n",
    "print(f\"Using \\\"{device}\\\" device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Define the Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델을 `nn.Module`의 하위 클래스로 정의하고, `__init__`에서 신경망 계층을 초기화한다.  \n",
    "`nn.Module`을 상속받은 모든 클래스는 `forward`메서드에 입력 데이터에 대한 연산을 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "      nn.Linear(28*28, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512,10),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 사용하기 위해 입력 데이터를 전달한다. (`model.forward()`를 직접 호출 금지!)  \n",
    "\n",
    "2차원 텐서를 반환한다. dim=0은 각 class에 대한 raw 예측값 10개가, dim=1에는 각 출력의 개별 값이 해당한다.  \n",
    "원시 예측값을 `nn.Softmax`모듈의 인스턴스에 통과시켜 예측 확률을 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([4], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device = device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **nn.Flatten**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 28x28의 2d image를 784 픽셀 값을 갖는 연속된 배열로 변환한다.  \n",
    "(dim=0의 minibatch 차원은 유지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 weight와 bias를 사용, linear transformation을 적용하는 모듈이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비선형 활성화(activation)은 모델의 입력과 출력 사이에 복잡한 관계(mapping)을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.3901, -0.2389,  0.6727, -0.3194, -0.0923,  0.5681, -0.2696,  0.4318,\n",
      "         -0.5285,  0.2241,  0.0937,  0.1581, -0.1288, -0.6696, -0.1783,  0.3399,\n",
      "          0.5657, -0.1515,  0.1272,  0.4814],\n",
      "        [-0.2644, -0.1849,  0.2582, -0.3479,  0.2606,  0.5526, -0.4986,  0.1423,\n",
      "         -0.5990,  0.2083,  0.1635,  0.2912, -0.2009, -0.4093,  0.0680,  0.2558,\n",
      "          0.2149, -0.1400, -0.1217,  0.1305],\n",
      "        [-0.3114, -0.0691,  0.5407, -0.2211, -0.0402,  0.4363, -0.3798,  0.2308,\n",
      "         -0.5657, -0.0215,  0.4165,  0.1139, -0.1962, -0.4698, -0.1555,  0.2599,\n",
      "          0.1547, -0.5283,  0.0491,  0.3362]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.6727, 0.0000, 0.0000, 0.5681, 0.0000, 0.4318, 0.0000,\n",
      "         0.2241, 0.0937, 0.1581, 0.0000, 0.0000, 0.0000, 0.3399, 0.5657, 0.0000,\n",
      "         0.1272, 0.4814],\n",
      "        [0.0000, 0.0000, 0.2582, 0.0000, 0.2606, 0.5526, 0.0000, 0.1423, 0.0000,\n",
      "         0.2083, 0.1635, 0.2912, 0.0000, 0.0000, 0.0680, 0.2558, 0.2149, 0.0000,\n",
      "         0.0000, 0.1305],\n",
      "        [0.0000, 0.0000, 0.5407, 0.0000, 0.0000, 0.4363, 0.0000, 0.2308, 0.0000,\n",
      "         0.0000, 0.4165, 0.1139, 0.0000, 0.0000, 0.0000, 0.2599, 0.1547, 0.0000,\n",
      "         0.0491, 0.3362]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순서를 갖는 모듈의 컨테이너이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "  flatten,\n",
    "  layer1,\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dim`매개변수는 값의 합이 1이 되는 차원을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 내부 많은 계층은 매개변수화(parameterize)된다. `nn.Module`을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적(track)되며, 모델의 `parameters()` 및 `named_parameters()` 메서드로 모든 매개변수에 접근 가능하게 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qwerty1029/opt/anaconda3/envs/virtual/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_1aidzjezue/croot/pytorch_1687856425340/work/aten/src/ATen/native/mps/operations/Indexing.mm:218.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0159,  0.0041, -0.0296,  ..., -0.0077,  0.0121,  0.0101],\n",
      "        [-0.0357, -0.0169,  0.0094,  ...,  0.0355, -0.0086,  0.0120]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0227, -0.0348], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0305, -0.0425, -0.0281,  ..., -0.0383, -0.0439,  0.0430],\n",
      "        [-0.0122,  0.0280, -0.0046,  ..., -0.0109, -0.0264, -0.0163]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0260, -0.0441], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0123,  0.0416, -0.0155,  ..., -0.0299,  0.0138,  0.0127],\n",
      "        [-0.0004,  0.0439, -0.0022,  ..., -0.0269,  0.0127,  0.0215]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0307,  0.0146], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5) # input tensor\n",
    "y = torch.zeros(3) # expected output\n",
    "w = torch.randn(5, 3, requires_grad = True)\n",
    "b = torch.randn(3, requires_grad = True)\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Tensors, Functions and Computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`w`와 `b`는 최적화를 해야 하는 매개변수이다. 따라서 이러한 변수에 대해 loss function의 gradient를 계산할 수 있어야 하므로, `requires_grad` 속성을 적용한다.  \n",
    "\n",
    "연산 그래프를 구성하기 위해 텐서에 적용하는 함수는 `Function` 클래스의 객체이다. 이 객체는 순전파 방향으로 함수를 계산하는 방법과, 역전파 단계에서 도함수(derivative)를 계산하는 방법을 내장한다. 역전파 함수에 대한 참조는 텐서의 `grad_fn`속성에 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x28fb9c880>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x28fb9ee00>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. Computing Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화를 위해 매개변수에 대한 손실함수의 도함수를 계산해야 한다.  \n",
    "즉, ${\\partial loss} \\over {\\partial w}$ 와 ${\\partial loss} \\over {\\partial b}$ 가 필요하다.  \n",
    "계산을 위해 `loss.backward()`를 호출한 후 `w.grad`와 `b.grad`에서 값을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0340, 0.2006, 0.2755],\n",
      "        [0.0340, 0.2006, 0.2755],\n",
      "        [0.0340, 0.2006, 0.2755],\n",
      "        [0.0340, 0.2006, 0.2755],\n",
      "        [0.0340, 0.2006, 0.2755]])\n",
      "tensor([0.0340, 0.2006, 0.2755])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3. Disabling Gradient Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습한 뒤 입력 데이터를 적용하기만 하는 경우와 같이 순전파 연산만 필요한 경우, 변화도 추적이 필요 없다. 연산 코드를 `torch.no_grad()` 블럭으로 둘러싸 연산 추적을 멈출 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "  z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서에 `detach()` 메서드를 사용하는 방법도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'reqiures_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(x, w)\u001b[38;5;241m+\u001b[39mb\n\u001b[1;32m      2\u001b[0m z_det \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mz_det\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreqiures_grad\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'reqiures_grad'"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.reqiures_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizing Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Prerequisite Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Number of Epochs** : 데이터셋을 반복하는 횟수\n",
    "* **Batch Size** : 매개변수 갱신 전 신경망을 통해 전파된 데이터 샘플의 수\n",
    "* **Learning Rate** : 각 배치/에폭에서 모델의 매개변수를 조절하는 비율.($\\alpha$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3. Optimization Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화 단계의 각 반복(iteration)을 **에폭(Epoch)**이라 부른다.  \n",
    "\n",
    "하나의 에폭은 두 부분으로 구성된다.\n",
    "* **The Train Loop** : 학습용 데이터셋을 반복하고 최적의 매개변수로 수렴\n",
    "* **The Validation/Test Loop** : 모델 성능이 개선되는지를 확인하기 위해 테스트 데이터셋을 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loop에서 최적화는 3단계로 이루어진다.  \n",
    "* `optimizer.zero_grad()`를 호출하여 gradient를 재설정한다. 기본적으로 gradient는 더해지기(add up) 때문에, 중복을 막기위해 명시적으로 0으로 설정.\n",
    "* `loss.backwards()`를. 호출하여 prediction loss를 역전파.\n",
    "* 변화도를 계산한 뒤 `optimizer.step()`을 호출하여 역전파 단계에서 수집된 변화도로 매개변수를 조정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4. Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      loss, current = loss.item(), (batch + 1) * len(X)\n",
    "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  test_loss, correct = 0,0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      pred = model(X)\n",
    "      test_loss += loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306594 [   64/60000]\n",
      "loss: 2.291153 [ 6464/60000]\n",
      "loss: 2.272516 [12864/60000]\n",
      "loss: 2.259020 [19264/60000]\n",
      "loss: 2.253352 [25664/60000]\n",
      "loss: 2.223792 [32064/60000]\n",
      "loss: 2.223578 [38464/60000]\n",
      "loss: 2.191885 [44864/60000]\n",
      "loss: 2.183599 [51264/60000]\n",
      "loss: 2.154202 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 2.146678 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.154269 [   64/60000]\n",
      "loss: 2.149766 [ 6464/60000]\n",
      "loss: 2.083484 [12864/60000]\n",
      "loss: 2.093733 [19264/60000]\n",
      "loss: 2.059607 [25664/60000]\n",
      "loss: 1.991294 [32064/60000]\n",
      "loss: 2.017833 [38464/60000]\n",
      "loss: 1.938146 [44864/60000]\n",
      "loss: 1.938174 [51264/60000]\n",
      "loss: 1.868316 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.865661 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.895043 [   64/60000]\n",
      "loss: 1.875481 [ 6464/60000]\n",
      "loss: 1.741712 [12864/60000]\n",
      "loss: 1.780182 [19264/60000]\n",
      "loss: 1.698347 [25664/60000]\n",
      "loss: 1.635119 [32064/60000]\n",
      "loss: 1.667984 [38464/60000]\n",
      "loss: 1.567656 [44864/60000]\n",
      "loss: 1.588190 [51264/60000]\n",
      "loss: 1.491200 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 1.506013 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.565526 [   64/60000]\n",
      "loss: 1.543528 [ 6464/60000]\n",
      "loss: 1.382750 [12864/60000]\n",
      "loss: 1.453953 [19264/60000]\n",
      "loss: 1.357950 [25664/60000]\n",
      "loss: 1.338338 [32064/60000]\n",
      "loss: 1.371874 [38464/60000]\n",
      "loss: 1.292479 [44864/60000]\n",
      "loss: 1.318643 [51264/60000]\n",
      "loss: 1.231216 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.252204 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.320145 [   64/60000]\n",
      "loss: 1.311859 [ 6464/60000]\n",
      "loss: 1.141349 [12864/60000]\n",
      "loss: 1.243062 [19264/60000]\n",
      "loss: 1.133384 [25664/60000]\n",
      "loss: 1.146239 [32064/60000]\n",
      "loss: 1.185395 [38464/60000]\n",
      "loss: 1.118595 [44864/60000]\n",
      "loss: 1.146026 [51264/60000]\n",
      "loss: 1.073168 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.090586 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.154259 [   64/60000]\n",
      "loss: 1.162041 [ 6464/60000]\n",
      "loss: 0.978208 [12864/60000]\n",
      "loss: 1.106378 [19264/60000]\n",
      "loss: 0.991221 [25664/60000]\n",
      "loss: 1.013857 [32064/60000]\n",
      "loss: 1.064300 [38464/60000]\n",
      "loss: 1.003646 [44864/60000]\n",
      "loss: 1.030402 [51264/60000]\n",
      "loss: 0.970888 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.983662 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.036828 [   64/60000]\n",
      "loss: 1.062289 [ 6464/60000]\n",
      "loss: 0.864220 [12864/60000]\n",
      "loss: 1.013938 [19264/60000]\n",
      "loss: 0.900540 [25664/60000]\n",
      "loss: 0.919771 [32064/60000]\n",
      "loss: 0.982832 [38464/60000]\n",
      "loss: 0.927013 [44864/60000]\n",
      "loss: 0.950020 [51264/60000]\n",
      "loss: 0.902065 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.910552 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.950388 [   64/60000]\n",
      "loss: 0.993119 [ 6464/60000]\n",
      "loss: 0.782652 [12864/60000]\n",
      "loss: 0.949390 [19264/60000]\n",
      "loss: 0.840722 [25664/60000]\n",
      "loss: 0.851536 [32064/60000]\n",
      "loss: 0.925317 [38464/60000]\n",
      "loss: 0.875044 [44864/60000]\n",
      "loss: 0.892453 [51264/60000]\n",
      "loss: 0.853073 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.858464 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.884667 [   64/60000]\n",
      "loss: 0.942478 [ 6464/60000]\n",
      "loss: 0.722305 [12864/60000]\n",
      "loss: 0.902382 [19264/60000]\n",
      "loss: 0.798574 [25664/60000]\n",
      "loss: 0.800791 [32064/60000]\n",
      "loss: 0.882203 [38464/60000]\n",
      "loss: 0.838701 [44864/60000]\n",
      "loss: 0.849648 [51264/60000]\n",
      "loss: 0.816218 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.819563 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.832594 [   64/60000]\n",
      "loss: 0.902894 [ 6464/60000]\n",
      "loss: 0.675706 [12864/60000]\n",
      "loss: 0.866794 [19264/60000]\n",
      "loss: 0.766855 [25664/60000]\n",
      "loss: 0.762202 [32064/60000]\n",
      "loss: 0.848176 [38464/60000]\n",
      "loss: 0.811856 [44864/60000]\n",
      "loss: 0.816466 [51264/60000]\n",
      "loss: 0.787069 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.788944 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.789556 [   64/60000]\n",
      "loss: 0.869983 [ 6464/60000]\n",
      "loss: 0.638463 [12864/60000]\n",
      "loss: 0.838927 [19264/60000]\n",
      "loss: 0.741273 [25664/60000]\n",
      "loss: 0.731942 [32064/60000]\n",
      "loss: 0.819837 [38464/60000]\n",
      "loss: 0.790730 [44864/60000]\n",
      "loss: 0.789935 [51264/60000]\n",
      "loss: 0.762945 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.763701 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.753044 [   64/60000]\n",
      "loss: 0.841428 [ 6464/60000]\n",
      "loss: 0.607494 [12864/60000]\n",
      "loss: 0.816093 [19264/60000]\n",
      "loss: 0.720179 [25664/60000]\n",
      "loss: 0.707546 [32064/60000]\n",
      "loss: 0.795089 [38464/60000]\n",
      "loss: 0.773278 [44864/60000]\n",
      "loss: 0.768037 [51264/60000]\n",
      "loss: 0.742385 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.742036 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.721216 [   64/60000]\n",
      "loss: 0.815842 [ 6464/60000]\n",
      "loss: 0.581130 [12864/60000]\n",
      "loss: 0.796890 [19264/60000]\n",
      "loss: 0.702018 [25664/60000]\n",
      "loss: 0.687390 [32064/60000]\n",
      "loss: 0.772729 [38464/60000]\n",
      "loss: 0.758184 [44864/60000]\n",
      "loss: 0.749285 [51264/60000]\n",
      "loss: 0.724317 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.722881 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.693002 [   64/60000]\n",
      "loss: 0.792445 [ 6464/60000]\n",
      "loss: 0.558234 [12864/60000]\n",
      "loss: 0.780098 [19264/60000]\n",
      "loss: 0.686092 [25664/60000]\n",
      "loss: 0.670283 [32064/60000]\n",
      "loss: 0.752052 [38464/60000]\n",
      "loss: 0.744862 [44864/60000]\n",
      "loss: 0.732794 [51264/60000]\n",
      "loss: 0.707911 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.705568 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.667650 [   64/60000]\n",
      "loss: 0.770838 [ 6464/60000]\n",
      "loss: 0.538083 [12864/60000]\n",
      "loss: 0.765098 [19264/60000]\n",
      "loss: 0.671819 [25664/60000]\n",
      "loss: 0.655671 [32064/60000]\n",
      "loss: 0.732781 [38464/60000]\n",
      "loss: 0.732709 [44864/60000]\n",
      "loss: 0.718244 [51264/60000]\n",
      "loss: 0.692904 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.689718 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.644772 [   64/60000]\n",
      "loss: 0.750801 [ 6464/60000]\n",
      "loss: 0.520169 [12864/60000]\n",
      "loss: 0.751483 [19264/60000]\n",
      "loss: 0.659188 [25664/60000]\n",
      "loss: 0.642935 [32064/60000]\n",
      "loss: 0.714806 [38464/60000]\n",
      "loss: 0.721686 [44864/60000]\n",
      "loss: 0.705301 [51264/60000]\n",
      "loss: 0.678977 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.675120 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.624087 [   64/60000]\n",
      "loss: 0.732220 [ 6464/60000]\n",
      "loss: 0.504151 [12864/60000]\n",
      "loss: 0.739031 [19264/60000]\n",
      "loss: 0.647968 [25664/60000]\n",
      "loss: 0.631851 [32064/60000]\n",
      "loss: 0.698011 [38464/60000]\n",
      "loss: 0.711872 [44864/60000]\n",
      "loss: 0.693896 [51264/60000]\n",
      "loss: 0.666050 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.661624 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.605225 [   64/60000]\n",
      "loss: 0.714869 [ 6464/60000]\n",
      "loss: 0.489774 [12864/60000]\n",
      "loss: 0.727493 [19264/60000]\n",
      "loss: 0.637899 [25664/60000]\n",
      "loss: 0.622051 [32064/60000]\n",
      "loss: 0.682227 [38464/60000]\n",
      "loss: 0.703083 [44864/60000]\n",
      "loss: 0.683870 [51264/60000]\n",
      "loss: 0.653866 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.649112 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.587977 [   64/60000]\n",
      "loss: 0.698713 [ 6464/60000]\n",
      "loss: 0.476793 [12864/60000]\n",
      "loss: 0.716803 [19264/60000]\n",
      "loss: 0.628808 [25664/60000]\n",
      "loss: 0.613357 [32064/60000]\n",
      "loss: 0.667406 [38464/60000]\n",
      "loss: 0.695379 [44864/60000]\n",
      "loss: 0.675133 [51264/60000]\n",
      "loss: 0.642353 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.637496 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.572185 [   64/60000]\n",
      "loss: 0.683679 [ 6464/60000]\n",
      "loss: 0.464958 [12864/60000]\n",
      "loss: 0.706828 [19264/60000]\n",
      "loss: 0.620606 [25664/60000]\n",
      "loss: 0.605615 [32064/60000]\n",
      "loss: 0.653500 [38464/60000]\n",
      "loss: 0.688652 [44864/60000]\n",
      "loss: 0.667538 [51264/60000]\n",
      "loss: 0.631351 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.626717 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 20\n",
    "for i in range(epochs):\n",
    "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "  test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-1. Saving and Loading Model Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 가중치 저장하기\n",
    "\n",
    "  PyTorch 모델은 학습한 매개변수를 `state_dict`라고 불리는 내부 상태 사전(internal state dictionary)에 저장한다. 이 상태 값들은 `torch.save` 메서드를 사용하여 저장(persist)할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/qwerty1029/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:59<00:00, 9.29MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 가중치 불러오기\n",
    "\n",
    "  먼저 동일한 모델의 인스턴스를 생성한 후, `load_state_dict()` 메서드를 사용하여 매개변수를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주의사항\n",
    "\n",
    "  추론(interference)을 하기 전, 반드시 `model.eval()`메서드를 호출하여 dropout과 batch normalization을 evaluation mode로 설정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-2. Saving and Loading Models with Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 가중치를 불러올 떄, 신경망의 구조를 정의하기 위해 모델 클래스를 먼저 생성해야 했다.  \n",
    "\n",
    "이 클래스의 구조를 모델과 함께 저장하고 싶으면, `model.state_dict()`가 아닌 `model`을 저장 함수에 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')\n",
    "\n",
    "model = torch.load('model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
